{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b77b7ac-3e50-462a-927a-61e9f6d656d9",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "# Snowflake Cortex AI - Transforming & Semantic Model Generation\n",
    "\n",
    "This notebook shows how you can use Large Language Models to help you transforming from raw, bronze to gold layer with the goal of generating a semantic model where users can ask questions using natural language. The bronze layer will have tables with column names that meaningful to Analyst. The Gold Layer will have the views that will be used by Cortex Analyst, Snowflake text-2-sql capability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555cbef-c78e-4f99-9061-90518e105534",
   "metadata": {
    "collapsed": false,
    "name": "variables_md"
   },
   "source": [
    "Change this definition in case you want to use other names or LLMs. Note this has been tested using the Anthropic model claude-3-5-sonnet. For LLM Region availability check: https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions or enable Cross-Region Support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0b949-d8f9-4a3d-a517-f361026eb030",
   "metadata": {
    "language": "python",
    "name": "variables"
   },
   "outputs": [],
   "source": [
    "LLM = 'claude-3-5-sonnet'\n",
    "RAW_LAYER = 'SAP_RAW'\n",
    "BRONZE_LAYER = 'SAP_BRONZE'\n",
    "GOLD_LAYER = 'SAP_GOLD'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b2ca9-7e67-4787-9d8d-7698ec1c4028",
   "metadata": {
    "collapsed": false,
    "name": "setup_1_md"
   },
   "source": [
    "Note this Notebook is expected to run in a test database and it will create a clean environment. This is replacing the BRONZE_LAYER schema in case it exists!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "setup_1"
   },
   "outputs": [],
   "source": [
    "session.sql(f'create or replace schema {BRONZE_LAYER}').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06e606-ec6a-479e-981f-a01d12ceeb79",
   "metadata": {
    "collapsed": false,
    "name": "bronze_generate_md"
   },
   "source": [
    "### Asking LLM how to generate new tables in BRONZE layer and copy from RAW\n",
    "\n",
    "Let's use the power of LLMs to translate column names into something meaningful for analyst and provide the SQL to crate new tables and copy the content from RAW ones. This will take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d0dde-3289-471d-9b2b-7d18a42d74c4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "bronze_generate"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "table_names = [\"fi_ar_4\", \"customer\", \"material\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for table in table_names:\n",
    "    \n",
    "    sql_text1 = f\"\"\"\n",
    "    select snowflake.cortex.complete('{LLM}', '\n",
    "    Generate a new SQL CREATE OR REPLACE table statement which will replace all \n",
    "    the below column names by easy and clear to understand column names for a \n",
    "    data analyst. Generate the SQL to copy the data from the source table to the\n",
    "    target table respecting the column names. \n",
    "    The data types should be kept the same. Source schema is called {RAW_LAYER}. \n",
    "    Target schema is called {BRONZE_LAYER}. \n",
    "    It should in run Snowflake.'  \n",
    "    || GET_DDL('table','{RAW_LAYER}.\"{table}\"') );\n",
    "    \"\"\"\n",
    "\n",
    "    full_text_str = session.sql(sql_text1).collect()[0][0]\n",
    "\n",
    "    # Extract content between ```sql and ```\n",
    "    match = re.search(r\"```sql(.*?)```\", full_text_str, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_sql = match.group(1).strip()\n",
    "        extracted_sql = extracted_sql.replace('\"', '\\\"')  # Double double-quotes for SQL safety\n",
    "\n",
    "    else:\n",
    "        extracted_sql = '\"\"\" \"\"\"'\n",
    "        \n",
    "    results[table] = {\n",
    "        \"table_name\": table,\n",
    "        \"full_output\": full_text_str,\n",
    "        \"extracted_sql\": extracted_sql\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb8494-e331-4447-89c8-d8d2fa7ea734",
   "metadata": {
    "language": "python",
    "name": "bronze_show"
   },
   "outputs": [],
   "source": [
    "# Visualize the results before executing. Click on each expander to review.\n",
    "for table, data in results.items():\n",
    "    with st.expander(f\"Full Output for Table: {data['table_name']}\"):\n",
    "        st.subheader(\"Full Output:\")\n",
    "        st.code(data[\"full_output\"], language=\"sql\")\n",
    "\n",
    "    with st.expander(f\"SQL for Table: {data['table_name']}\"):\n",
    "        st.subheader(\"Extracted SQL:\")\n",
    "        st.code(data[\"extracted_sql\"], language=\"sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf96f9-c0cd-45ce-8d2b-667c9ce385d7",
   "metadata": {
    "collapsed": false,
    "name": "bronze_create_md"
   },
   "source": [
    "If you are ok with the output, run next cell to extract the SQL provided to CREATE the new table and the one to INSERT the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdc130-9e24-4624-833c-1ed4c655add0",
   "metadata": {
    "language": "python",
    "name": "bronze_create"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "create_sql_statements = \"\"\n",
    "\n",
    "for table, data in results.items():\n",
    "    extracted_sql = data[\"extracted_sql\"]\n",
    "\n",
    "    # Updated regex to ensure we capture full CREATE and INSERT statements ending in ');'\n",
    "    sql_statements = re.split(r';\\s*\\n', extracted_sql.strip())\n",
    "    \n",
    "    # Extracting the CREATE TABLE and INSERT statements\n",
    "    create_table_sql = sql_statements[0] + \";\"\n",
    "    insert_sql = sql_statements[1] + \";\"\n",
    "    \n",
    "    print(f\"CREATING TABLE: {table}\")\n",
    "    session.sql(create_table_sql).collect()\n",
    "    create_sql_statements += create_table_sql\n",
    "    \n",
    "    print(f\"INSERT INTO TABLE {table}:\")\n",
    "    session.sql(insert_sql).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f9a7e-69f9-4bc9-8636-64c2474e1b56",
   "metadata": {
    "language": "sql",
    "name": "bronze_review"
   },
   "outputs": [],
   "source": [
    "-- One of the advantages of Snowflake Notebooks is that you can combine Python, SQL and Markdown! Let's see what tables we got in this layer:\n",
    "show tables;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3e9e2-e690-4c00-bffd-535ea60f9a64",
   "metadata": {
    "language": "sql",
    "name": "bronze_review2"
   },
   "outputs": [],
   "source": [
    "table ACCOUNTS_RECEIVABLE limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc973f7-62df-4043-ae4a-7bdc042a152a",
   "metadata": {
    "collapsed": false,
    "name": "gold_generate_md"
   },
   "source": [
    "### Generating GOLD Layer\n",
    "\n",
    "Let's use the power of LLMs to create a Data MART with the previous tables. This will contain the most important information joining the 3 tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a730b-f5cf-47ce-980d-d9de7405fa29",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "gold_generate"
   },
   "outputs": [],
   "source": [
    "sql_text2 = f\"\"\"\n",
    "select snowflake.cortex.complete('{LLM}', '\n",
    "Generate a single SQL statement which creates a Data mart table called ACCOUNTS_RECEIVABLE_MART selecting 25 most representative columns and joining the key columns properly.\n",
    "It should include a column CUSTOMER_NAME, a posting date and clearing date and other information for each financial document, as well as the information necessary to calculate Days Sales Outstanding per customer \n",
    "Create the new table under {GOLD_LAYER} schema.\n",
    "These are the tables to be used:\n",
    "{create_sql_statements}');\n",
    "\"\"\"\n",
    "\n",
    "full_text_str2 = session.sql(sql_text2).collect()[0][0]\n",
    "\n",
    "# Extract content between ```sql and ```\n",
    "match = re.search(r\"```sql(.*?)```\", full_text_str2, re.DOTALL)\n",
    "if match:\n",
    "    extracted_sql2 = match.group(1).strip()\n",
    "    extracted_sql2 = extracted_sql2.replace('\"', '\\\"')  # Double double-quotes for SQL safety\n",
    "\n",
    "else:\n",
    "    extracted_sql2 = '\"\"\" \"\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af60a6-6491-4199-a019-bdc1e111ffa6",
   "metadata": {
    "language": "python",
    "name": "gold_show"
   },
   "outputs": [],
   "source": [
    "with st.expander(f\"Full Explanation:\"):\n",
    "    st.code(full_text_str2, language=\"sql\")\n",
    "\n",
    "with st.expander(f\"SQL to build Mart:\"):\n",
    "    st.code(extracted_sql2, language=\"sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19965abd-372b-4703-9842-4b7a2224e318",
   "metadata": {
    "language": "python",
    "name": "gold_create"
   },
   "outputs": [],
   "source": [
    "session.sql('create or replace schema SAP_GOLD').collect()\n",
    "session.sql(extracted_sql2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320ef68-c41a-4438-b148-8f0cbd50b16d",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "gold_review"
   },
   "outputs": [],
   "source": [
    "table accounts_receivable_mart;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3755f9-1067-4e91-9220-9bca54e88f69",
   "metadata": {
    "collapsed": false,
    "name": "semantic_search_create_md"
   },
   "source": [
    "### Semantic Model: Cortex Search and Cortex Analyst\n",
    "\n",
    "Using Snowflake Snowsight UI, we are going to create the Semantic Model that will be used by Cortex Analys to allow business users ask questions in natural language.\n",
    "\n",
    "As we have a large number of CUSTOMER_NAME distinct values, and Analyst may want to ask for any of them, we are going to use the integration of Cortex Search and Cortex Analyst. \n",
    "\n",
    "Cortex Search will be enabled on those columns, so Cortex Analyst can retrieval names when needed, without having to provide all possible names in the semantic file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fb0c5-6fa0-4af1-9434-8b242d0fcbbd",
   "metadata": {
    "language": "python",
    "name": "semantic_search_create"
   },
   "outputs": [],
   "source": [
    "session.sql(f''' \n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE {GOLD_LAYER}.CUSTOMER_NAME_SEARCH \n",
    "ON CUSTOMER_NAME \n",
    "WAREHOUSE = COMPUTE_WH  \n",
    "TARGET_LAG = '1 day' \n",
    "EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0' \n",
    "AS (SELECT DISTINCT CUSTOMER_NAME FROM {GOLD_LAYER}.accounts_receivable_mart);\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f6d3d-d460-4074-8ffd-689ddb0a473f",
   "metadata": {
    "language": "python",
    "name": "semantic_questions_generate"
   },
   "outputs": [],
   "source": [
    "extracted_sql3 = extracted_sql2.replace(\"'\", '')  # handle exceptions by removing single quotes\n",
    "\n",
    "sql_text3 = f\"\"\"\n",
    "select snowflake.cortex.complete('{LLM}', ' Provide 5 examples of questions that can be asked to this data mart, with the associated SQL query to answer this question: {extracted_sql3}');\n",
    "\"\"\"\n",
    "\n",
    "full_text_str3 = session.sql(sql_text3).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2373b9-2c69-42b7-8a6f-aacb1062e68a",
   "metadata": {
    "language": "python",
    "name": "semantic_questions_show"
   },
   "outputs": [],
   "source": [
    "with st.expander(\"Questions:\"):\n",
    "    st.code(full_text_str3, language=\"sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae02169-ce9b-47ff-8968-401b90023aff",
   "metadata": {
    "collapsed": false,
    "name": "semantic_questions_review"
   },
   "source": [
    "Examples of questions :\n",
    "\n",
    "what's the top 10 of customers who takes the longest to pay (clear a facture) on average ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "carlos.carrero@snowflake.com",
   "authorId": "5744486210470",
   "authorName": "CCARRERO",
   "lastEditTime": 1742910224688,
   "notebookId": "ml23el25pne273aftwn7",
   "sessionId": "7718a8fb-4e54-4a03-9196-f328f1db3e68"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
